{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf5ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def read_processed_tickers(file_path):\n",
    "    \"\"\"\n",
    "    Safely read the processed tickers file without disrupting ongoing writes.\n",
    "    Returns a set of processed ticker symbols.\n",
    "    \"\"\"\n",
    "    processed_tickers = set()\n",
    "\n",
    "    # Check if file exists first\n",
    "    if not os.path.exists(file_path):\n",
    "        return processed_tickers\n",
    "\n",
    "    try:\n",
    "        # Try a few times in case the file is being written to\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                with open(file_path, \"r\") as f:\n",
    "                    return set(line.strip() for line in f if line.strip())\n",
    "            except (IOError, PermissionError) as e:\n",
    "                # If there's a file access issue, wait briefly and retry\n",
    "                if attempt < max_attempts - 1:\n",
    "                    print(\n",
    "                        f\"Attempt {attempt+1} to read {file_path} failed: {e}. Retrying...\"\n",
    "                    )\n",
    "                    time.sleep(0.5)\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Failed to read processed tickers after {max_attempts} attempts: {e}\"\n",
    "                    )\n",
    "                    raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading processed tickers file: {e}\")\n",
    "\n",
    "    return processed_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dc1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ticker_from_processed(lbw, ticker_to_remove):\n",
    "    \"\"\"\n",
    "    Remove a specific ticker from the processed_tickers.txt file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lbw : int\n",
    "        Lookback window length\n",
    "    ticker_to_remove : str\n",
    "        Ticker symbol to remove from the processed list\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from settings.default import CPD_OPENBB_OUTPUT_FOLDER\n",
    "\n",
    "    # Get the path to the processed_tickers.txt file\n",
    "    progress_file = os.path.join(\n",
    "        CPD_OPENBB_OUTPUT_FOLDER(lbw), \"processed_tickers.txt\"\n",
    "    )\n",
    "\n",
    "    # Read the current list of processed tickers\n",
    "    try:\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            tickers = [line.strip() for line in f if line.strip()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {progress_file} not found.\")\n",
    "        return\n",
    "\n",
    "    # Check if ticker exists in the list\n",
    "    if ticker_to_remove not in tickers:\n",
    "        print(\n",
    "            f\"Ticker '{ticker_to_remove}' not found in processed tickers list.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Remove the ticker from the list\n",
    "    tickers.remove(ticker_to_remove)\n",
    "\n",
    "    # Write the updated list back to the file\n",
    "    with open(progress_file, \"w\") as f:\n",
    "        for ticker in tickers:\n",
    "            f.write(f\"{ticker}\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"Successfully removed '{ticker_to_remove}' from processed tickers list.\"\n",
    "    )\n",
    "    print(f\"Remaining tickers: {tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337d4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tickers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90211de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processed 35 tickers\n",
      "Processed tickers: {'DX', 'CL', 'RP', 'ZC', 'NG', 'ZS', '6J', 'RY', 'ZW', 'SB', 'CT', 'HG', 'SY', 'RB', 'OJ', 'SI', 'GC', 'ZN', 'HO', 'SS', 'CC', 'YM', 'ZB', 'QG', '6Z', 'ZJ', '6C', 'ES', 'ZF', 'RF', 'ZR', 'AR', 'QM', 'NQ', 'KC'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from settings.default import CPD_OPENBB_OUTPUT_FOLDER\n",
    "\n",
    "# Example usage:\n",
    "lbw = 21  # Your lookback window length\n",
    "progress_file = os.path.join(\n",
    "    CPD_OPENBB_OUTPUT_FOLDER(lbw), \"processed_tickers.txt\"\n",
    ")\n",
    "processed_tickers[lbw] = read_processed_tickers(progress_file)\n",
    "print(f\"Currently processed {len(processed_tickers[lbw])} tickers\")\n",
    "print(f\"Processed tickers: {processed_tickers[lbw]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89ddd2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processed 35 tickers\n",
      "Processed tickers: {'DX', 'CL', 'RP', 'ZC', 'NG', 'ZS', '6J', 'RY', 'ZW', 'SB', 'CT', 'HG', 'RB', 'SY', 'OJ', 'SI', 'GC', 'ZN', 'HO', 'SS', 'CC', 'YM', 'ZB', 'QG', '6Z', 'ZJ', '6C', 'ES', 'ZF', 'RF', 'ZR', 'AR', 'QM', 'NQ', 'KC'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "lbw = 126  # Your lookback window length\n",
    "progress_file = os.path.join(\n",
    "    CPD_OPENBB_OUTPUT_FOLDER(lbw), \"processed_tickers.txt\"\n",
    ")\n",
    "processed_tickers[lbw] = read_processed_tickers(progress_file)\n",
    "print(f\"Currently processed {len(processed_tickers[lbw])} tickers\")\n",
    "print(f\"Processed tickers: {processed_tickers[lbw]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072280bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common tickers for lbw 21 and 126: ['HO']\n"
     ]
    }
   ],
   "source": [
    "# Which tickers have been processed for both lbw?\n",
    "common_tickers = set(processed_tickers[21]) - set(processed_tickers[126])\n",
    "print(f\"Common tickers for lbw 21 and 126: {list(common_tickers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39edd85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date ranges for LBW = 21:\n",
      "6C: 2000-08-24 to 2021-12-30\n",
      "6J: 2001-01-10 to 2021-12-28\n",
      "6Z: 2011-06-24 to 2018-06-28\n",
      "AR: Empty file to No data\n",
      "CC: 2006-10-17 to 2019-05-15\n",
      "CL: 2004-01-23 to 2019-12-23\n",
      "CT: 2000-02-02 to 2021-12-29\n",
      "DX: 2008-06-26 to 2016-06-27\n",
      "ES: 2000-10-17 to 2021-12-30\n",
      "GC: 2000-09-29 to 2021-12-30\n",
      "HG: 2000-09-29 to 2021-12-30\n",
      "HO: 2000-10-03 to 2021-12-30\n",
      "KC: 2000-02-02 to 2021-12-30\n",
      "NG: 2014-10-13 to 2021-12-30\n",
      "NQ: 2001-04-10 to 2021-12-30\n",
      "OJ: 2010-12-14 to 2021-12-30\n",
      "QG: 2009-05-15 to 2021-12-30\n",
      "QM: 2010-04-01 to 2021-12-30\n",
      "RB: 2006-04-19 to 2021-12-30\n",
      "RF: 2006-11-09 to 2021-12-30\n",
      "RP: 2007-03-16 to 2021-12-30\n",
      "RY: 2000-08-18 to 2021-12-30\n",
      "SB: 2007-01-30 to 2021-12-30\n",
      "SI: 2004-02-02 to 2021-12-30\n",
      "SS: 2012-04-04 to 2021-12-30\n",
      "SY: 2016-04-29 to 2021-12-30\n",
      "YM: 2008-07-29 to 2021-12-30\n",
      "ZB: 2006-08-15 to 2021-12-30\n",
      "ZC: 2007-06-22 to 2021-12-30\n",
      "ZF: 2013-01-04 to 2021-12-30\n",
      "ZJ: 2003-08-07 to 2021-12-30\n",
      "ZN: 2005-04-21 to 2021-12-30\n",
      "ZR: 2003-09-12 to 2021-12-30\n",
      "ZS: Empty file to No data\n",
      "ZW: 2006-10-18 to 2021-12-30\n",
      "\n",
      "Date ranges for LBW = 126:\n",
      "6C: Empty file to No data\n",
      "6J: 2001-07-12 to 2007-08-15\n",
      "6Z: 2001-10-08 to 2019-12-11\n",
      "AR: 2003-09-15 to 2015-02-19\n",
      "CC: 2000-07-05 to 2011-12-27\n",
      "CL: 2001-02-26 to 2012-07-09\n",
      "CT: 2000-07-05 to 2011-09-16\n",
      "DX: 2000-12-18 to 2012-05-24\n",
      "ES: 2001-03-20 to 2012-07-25\n",
      "GC: 2001-03-05 to 2004-02-09\n",
      "HG: 2001-03-05 to 2021-12-30\n",
      "HO: Empty file to No data\n",
      "KC: 2006-08-29 to 2021-12-30\n",
      "NG: 2007-09-25 to 2021-12-30\n",
      "NQ: Empty file to No data\n",
      "OJ: 2011-03-04 to 2021-12-30\n",
      "QG: 2016-03-23 to 2021-12-30\n",
      "QM: Empty file to No data\n",
      "RB: 2015-07-27 to 2021-12-30\n",
      "RF: 2008-07-02 to 2021-12-30\n",
      "RP: 2000-03-24 to 2021-12-30\n",
      "RY: 2006-03-17 to 2021-12-30\n",
      "SB: 2004-01-08 to 2021-12-30\n",
      "SI: 2017-09-19 to 2021-12-30\n",
      "SS: 2007-08-07 to 2021-12-30\n",
      "SY: 2008-10-14 to 2021-12-30\n",
      "YM: 2002-10-03 to 2021-12-30\n",
      "ZB: 2006-12-01 to 2021-12-30\n",
      "ZC: 2006-12-20 to 2021-12-30\n",
      "ZF: 2007-03-12 to 2021-12-30\n",
      "ZJ: 2014-04-15 to 2021-12-30\n",
      "ZN: 2008-09-12 to 2021-12-30\n",
      "ZR: 2009-03-12 to 2021-12-30\n",
      "ZS: 2014-04-15 to 2021-12-30\n",
      "ZW: Empty file to No data\n",
      "\n",
      "Tickers with different date ranges between LBW 21 and 126:\n",
      "DX:\n",
      "  LBW 21: 2008-06-26 to 2016-06-27\n",
      "  LBW 126: 2000-12-18 to 2012-05-24\n",
      "CL:\n",
      "  LBW 21: 2004-01-23 to 2019-12-23\n",
      "  LBW 126: 2001-02-26 to 2012-07-09\n",
      "RP:\n",
      "  LBW 21: 2007-03-16 to 2021-12-30\n",
      "  LBW 126: 2000-03-24 to 2021-12-30\n",
      "ZC:\n",
      "  LBW 21: 2007-06-22 to 2021-12-30\n",
      "  LBW 126: 2006-12-20 to 2021-12-30\n",
      "NG:\n",
      "  LBW 21: 2014-10-13 to 2021-12-30\n",
      "  LBW 126: 2007-09-25 to 2021-12-30\n",
      "ZS:\n",
      "  LBW 21: Empty file to No data\n",
      "  LBW 126: 2014-04-15 to 2021-12-30\n",
      "NQ:\n",
      "  LBW 21: 2001-04-10 to 2021-12-30\n",
      "  LBW 126: Empty file to No data\n",
      "6J:\n",
      "  LBW 21: 2001-01-10 to 2021-12-28\n",
      "  LBW 126: 2001-07-12 to 2007-08-15\n",
      "RY:\n",
      "  LBW 21: 2000-08-18 to 2021-12-30\n",
      "  LBW 126: 2006-03-17 to 2021-12-30\n",
      "ZW:\n",
      "  LBW 21: 2006-10-18 to 2021-12-30\n",
      "  LBW 126: Empty file to No data\n",
      "SB:\n",
      "  LBW 21: 2007-01-30 to 2021-12-30\n",
      "  LBW 126: 2004-01-08 to 2021-12-30\n",
      "CT:\n",
      "  LBW 21: 2000-02-02 to 2021-12-29\n",
      "  LBW 126: 2000-07-05 to 2011-09-16\n",
      "HG:\n",
      "  LBW 21: 2000-09-29 to 2021-12-30\n",
      "  LBW 126: 2001-03-05 to 2021-12-30\n",
      "RB:\n",
      "  LBW 21: 2006-04-19 to 2021-12-30\n",
      "  LBW 126: 2015-07-27 to 2021-12-30\n",
      "SY:\n",
      "  LBW 21: 2016-04-29 to 2021-12-30\n",
      "  LBW 126: 2008-10-14 to 2021-12-30\n",
      "OJ:\n",
      "  LBW 21: 2010-12-14 to 2021-12-30\n",
      "  LBW 126: 2011-03-04 to 2021-12-30\n",
      "SI:\n",
      "  LBW 21: 2004-02-02 to 2021-12-30\n",
      "  LBW 126: 2017-09-19 to 2021-12-30\n",
      "GC:\n",
      "  LBW 21: 2000-09-29 to 2021-12-30\n",
      "  LBW 126: 2001-03-05 to 2004-02-09\n",
      "ZN:\n",
      "  LBW 21: 2005-04-21 to 2021-12-30\n",
      "  LBW 126: 2008-09-12 to 2021-12-30\n",
      "HO:\n",
      "  LBW 21: 2000-10-03 to 2021-12-30\n",
      "  LBW 126: Empty file to No data\n",
      "CC:\n",
      "  LBW 21: 2006-10-17 to 2019-05-15\n",
      "  LBW 126: 2000-07-05 to 2011-12-27\n",
      "YM:\n",
      "  LBW 21: 2008-07-29 to 2021-12-30\n",
      "  LBW 126: 2002-10-03 to 2021-12-30\n",
      "ZB:\n",
      "  LBW 21: 2006-08-15 to 2021-12-30\n",
      "  LBW 126: 2006-12-01 to 2021-12-30\n",
      "QG:\n",
      "  LBW 21: 2009-05-15 to 2021-12-30\n",
      "  LBW 126: 2016-03-23 to 2021-12-30\n",
      "6Z:\n",
      "  LBW 21: 2011-06-24 to 2018-06-28\n",
      "  LBW 126: 2001-10-08 to 2019-12-11\n",
      "ZJ:\n",
      "  LBW 21: 2003-08-07 to 2021-12-30\n",
      "  LBW 126: 2014-04-15 to 2021-12-30\n",
      "6C:\n",
      "  LBW 21: 2000-08-24 to 2021-12-30\n",
      "  LBW 126: Empty file to No data\n",
      "ES:\n",
      "  LBW 21: 2000-10-17 to 2021-12-30\n",
      "  LBW 126: 2001-03-20 to 2012-07-25\n",
      "ZF:\n",
      "  LBW 21: 2013-01-04 to 2021-12-30\n",
      "  LBW 126: 2007-03-12 to 2021-12-30\n",
      "RF:\n",
      "  LBW 21: 2006-11-09 to 2021-12-30\n",
      "  LBW 126: 2008-07-02 to 2021-12-30\n",
      "ZR:\n",
      "  LBW 21: 2003-09-12 to 2021-12-30\n",
      "  LBW 126: 2009-03-12 to 2021-12-30\n",
      "AR:\n",
      "  LBW 21: Empty file to No data\n",
      "  LBW 126: 2003-09-15 to 2015-02-19\n",
      "QM:\n",
      "  LBW 21: 2010-04-01 to 2021-12-30\n",
      "  LBW 126: Empty file to No data\n",
      "SS:\n",
      "  LBW 21: 2012-04-04 to 2021-12-30\n",
      "  LBW 126: 2007-08-07 to 2021-12-30\n",
      "KC:\n",
      "  LBW 21: 2000-02-02 to 2021-12-30\n",
      "  LBW 126: 2006-08-29 to 2021-12-30\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from settings.default import CPD_OPENBB_OUTPUT_FOLDER\n",
    "\n",
    "\n",
    "def get_ticker_date_ranges(lbw, tickers):\n",
    "    \"\"\"\n",
    "    Get the date range for each processed ticker's data file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lbw : int\n",
    "        Lookback window length\n",
    "    tickers : list or set\n",
    "        List of ticker symbols to check\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict: Dictionary mapping tickers to their (start_date, end_date) tuples\n",
    "    \"\"\"\n",
    "    date_ranges = {}\n",
    "    folder_path = CPD_OPENBB_OUTPUT_FOLDER(lbw)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        file_path = os.path.join(folder_path, f\"{ticker}.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                # Read the CSV file\n",
    "                df = pd.read_csv(file_path, index_col=0, parse_dates=True)\n",
    "                if not df.empty:\n",
    "                    start_date = df.index.min().strftime(\"%Y-%m-%d\")\n",
    "                    end_date = df.index.max().strftime(\"%Y-%m-%d\")\n",
    "                    date_ranges[ticker] = (start_date, end_date)\n",
    "                else:\n",
    "                    date_ranges[ticker] = (\"Empty file\", \"No data\")\n",
    "            except Exception as e:\n",
    "                date_ranges[ticker] = (f\"Error: {str(e)}\", \"\")\n",
    "        else:\n",
    "            date_ranges[ticker] = (\"File not found\", \"\")\n",
    "\n",
    "    return date_ranges\n",
    "\n",
    "\n",
    "# Print date ranges for lookback window 21\n",
    "print(\"Date ranges for LBW = 21:\")\n",
    "date_ranges_21 = get_ticker_date_ranges(21, processed_tickers[21])\n",
    "for ticker, (start_date, end_date) in sorted(date_ranges_21.items()):\n",
    "    print(f\"{ticker}: {start_date} to {end_date}\")\n",
    "\n",
    "print(\"\\nDate ranges for LBW = 126:\")\n",
    "date_ranges_126 = get_ticker_date_ranges(126, processed_tickers[126])\n",
    "for ticker, (start_date, end_date) in sorted(date_ranges_126.items()):\n",
    "    print(f\"{ticker}: {start_date} to {end_date}\")\n",
    "\n",
    "# Find tickers with different date ranges between the two lookback windows\n",
    "print(\"\\nTickers with different date ranges between LBW 21 and 126:\")\n",
    "common_tickers = set(processed_tickers[21]) & set(processed_tickers[126])\n",
    "for ticker in common_tickers:\n",
    "    if ticker in date_ranges_21 and ticker in date_ranges_126:\n",
    "        if date_ranges_21[ticker] != date_ranges_126[ticker]:\n",
    "            print(f\"{ticker}:\")\n",
    "            print(\n",
    "                f\"  LBW 21: {date_ranges_21[ticker][0]} to {date_ranges_21[ticker][1]}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"  LBW 126: {date_ranges_126[ticker][0]} to {date_ranges_126[ticker][1]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6af0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing tickers from LBW = 21...\n",
      "Found 10 tickers with start date after 2007:\n",
      "['DX', 'NG', 'SY', 'OJ', 'SS', 'YM', 'QG', '6Z', 'ZF', 'QM']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from settings.default import CPD_OPENBB_OUTPUT_FOLDER\n",
    "\n",
    "\n",
    "def merge_ticker_data_from_alt_dir(ticker, lbw=21):\n",
    "    \"\"\"\n",
    "    Merge data for a specific ticker from alternate directory and sort by date\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Ticker symbol\n",
    "    lbw : int\n",
    "        Lookback window length (default 21)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool: True if merge was successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    main_dir = CPD_OPENBB_OUTPUT_FOLDER(lbw)\n",
    "    alt_dir = os.path.join(os.path.dirname(main_dir), \"openbb_cpd_21lbw(1)\")\n",
    "\n",
    "    main_file = os.path.join(main_dir, f\"{ticker}.csv\")\n",
    "    alt_file = os.path.join(alt_dir, f\"{ticker}.csv\")\n",
    "\n",
    "    # Check if both files exist\n",
    "    if not os.path.exists(main_file):\n",
    "        print(f\"Main file for {ticker} doesn't exist in {main_dir}\")\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(alt_file):\n",
    "        print(f\"Alternative file for {ticker} doesn't exist in {alt_dir}\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # Read both files\n",
    "        print(f\"Reading data from {main_file}...\")\n",
    "        main_data = pd.read_csv(main_file, parse_dates=[\"date\"])\n",
    "\n",
    "        print(f\"Reading data from {alt_file}...\")\n",
    "        alt_data = pd.read_csv(alt_file, parse_dates=[\"date\"])\n",
    "\n",
    "        # Display stats before merging\n",
    "        print(f\"\\nBefore merging:\")\n",
    "        print(\n",
    "            f\"Main data: {len(main_data)} rows, from {main_data['date'].min()} to {main_data['date'].max()}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Alt data: {len(alt_data)} rows, from {alt_data['date'].min()} to {alt_data['date'].max()}\"\n",
    "        )\n",
    "\n",
    "        # Combine datasets\n",
    "        combined_data = pd.concat([main_data, alt_data])\n",
    "\n",
    "        # Remove duplicates (if any)\n",
    "        combined_data = combined_data.drop_duplicates(\n",
    "            subset=[\"date\"]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        # Sort by date\n",
    "        combined_data = combined_data.sort_values(\"date\")\n",
    "\n",
    "        # Display stats after merging\n",
    "        print(f\"\\nAfter merging:\")\n",
    "        print(\n",
    "            f\"Combined data: {len(combined_data)} rows, from {combined_data['date'].min()} to {combined_data['date'].max()}\"\n",
    "        )\n",
    "\n",
    "        # Create backup of original file\n",
    "        backup_file = main_file + \".bak\"\n",
    "        print(f\"\\nCreating backup of original file at {backup_file}\")\n",
    "        main_data.to_csv(backup_file, index=False)\n",
    "\n",
    "        # Save the merged data\n",
    "        print(f\"Saving merged data to {main_file}\")\n",
    "        combined_data.to_csv(main_file, index=False)\n",
    "\n",
    "        print(f\"Merge and sort complete for {ticker}!\")\n",
    "\n",
    "        # Also update progress file if needed\n",
    "        progress_file = main_file + \".progress\"\n",
    "        alt_progress_file = alt_file + \".progress\"\n",
    "\n",
    "        if os.path.exists(progress_file) and os.path.exists(alt_progress_file):\n",
    "            print(f\"Merging progress files for {ticker}...\")\n",
    "            # Read both sets of processed windows\n",
    "            with open(progress_file, \"r\") as f:\n",
    "                main_processed = set(\n",
    "                    int(line.strip()) for line in f.readlines()\n",
    "                )\n",
    "\n",
    "            with open(alt_progress_file, \"r\") as f:\n",
    "                alt_processed = set(\n",
    "                    int(line.strip()) for line in f.readlines()\n",
    "                )\n",
    "\n",
    "            # Combine processed windows\n",
    "            all_processed = main_processed.union(alt_processed)\n",
    "\n",
    "            # Create backup of original progress file\n",
    "            with open(progress_file + \".bak\", \"w\") as f:\n",
    "                for window in sorted(main_processed):\n",
    "                    f.write(f\"{window}\\n\")\n",
    "\n",
    "            # Write combined progress file\n",
    "            with open(progress_file, \"w\") as f:\n",
    "                for window in sorted(all_processed):\n",
    "                    f.write(f\"{window}\\n\")\n",
    "\n",
    "            print(\n",
    "                f\"Updated progress file with {len(all_processed)} processed windows\"\n",
    "            )\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging data for {ticker}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# First, get all tickers with a starting date after 2007\n",
    "lbw = 21\n",
    "print(f\"Analyzing tickers from LBW = {lbw}...\")\n",
    "\n",
    "# Get date ranges for all tickers\n",
    "date_ranges = get_ticker_date_ranges(lbw, processed_tickers[lbw])\n",
    "\n",
    "# Filter for tickers with start date after 2007\n",
    "post_2007_tickers = []\n",
    "for ticker, (start_date, end_date) in date_ranges.items():\n",
    "    try:\n",
    "        if (\n",
    "            isinstance(start_date, str)\n",
    "            and not start_date.startswith(\"Error\")\n",
    "            and not start_date.startswith(\"Empty\")\n",
    "        ):\n",
    "            start_year = datetime.strptime(start_date, \"%Y-%m-%d\").year\n",
    "            if start_year > 2007:\n",
    "                post_2007_tickers.append(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing date for {ticker}: {str(e)}\")\n",
    "\n",
    "print(f\"Found {len(post_2007_tickers)} tickers with start date after 2007:\")\n",
    "print(post_2007_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db01dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing ticker 1/5: 6Z\n",
      "Reading data from data\\openbb_cpd_21lbw\\6Z.csv...\n",
      "Reading data from data\\openbb_cpd_21lbw(1)\\6Z.csv...\n",
      "\n",
      "Before merging:\n",
      "Main data: 883 rows, from 2018-06-29 00:00:00 to 2021-12-30 00:00:00\n",
      "Alt data: 1530 rows, from 2001-05-03 00:00:00 to 2007-06-15 00:00:00\n",
      "\n",
      "After merging:\n",
      "Combined data: 2413 rows, from 2001-05-03 00:00:00 to 2021-12-30 00:00:00\n",
      "\n",
      "Creating backup of original file at data\\openbb_cpd_21lbw\\6Z.csv.bak\n",
      "Saving merged data to data\\openbb_cpd_21lbw\\6Z.csv\n",
      "Merge and sort complete for 6Z!\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing ticker 2/5: CL\n",
      "Reading data from data\\openbb_cpd_21lbw\\CL.csv...\n",
      "Reading data from data\\openbb_cpd_21lbw(1)\\CL.csv...\n",
      "\n",
      "Before merging:\n",
      "Main data: 1081 rows, from 2017-06-14 00:00:00 to 2021-12-30 00:00:00\n",
      "Alt data: 828 rows, from 2000-09-22 00:00:00 to 2004-01-22 00:00:00\n",
      "\n",
      "After merging:\n",
      "Combined data: 1909 rows, from 2000-09-22 00:00:00 to 2021-12-30 00:00:00\n",
      "\n",
      "Creating backup of original file at data\\openbb_cpd_21lbw\\CL.csv.bak\n",
      "Saving merged data to data\\openbb_cpd_21lbw\\CL.csv\n",
      "Merge and sort complete for CL!\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing ticker 3/5: DX\n",
      "Reading data from data\\openbb_cpd_21lbw\\DX.csv...\n",
      "Reading data from data\\openbb_cpd_21lbw(1)\\DX.csv...\n",
      "\n",
      "Before merging:\n",
      "Main data: 1386 rows, from 2016-06-28 00:00:00 to 2021-12-30 00:00:00\n",
      "Alt data: 1499 rows, from 2000-07-24 00:00:00 to 2006-06-05 00:00:00\n",
      "\n",
      "After merging:\n",
      "Combined data: 2885 rows, from 2000-07-24 00:00:00 to 2021-12-30 00:00:00\n",
      "\n",
      "Creating backup of original file at data\\openbb_cpd_21lbw\\DX.csv.bak\n",
      "Saving merged data to data\\openbb_cpd_21lbw\\DX.csv\n",
      "Merge and sort complete for DX!\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing ticker 4/5: CC\n",
      "Reading data from data\\openbb_cpd_21lbw\\CC.csv...\n",
      "Reading data from data\\openbb_cpd_21lbw(1)\\CC.csv...\n",
      "\n",
      "Before merging:\n",
      "Main data: 663 rows, from 2019-05-16 00:00:00 to 2021-12-30 00:00:00\n",
      "Alt data: 1671 rows, from 2000-02-02 00:00:00 to 2006-10-16 00:00:00\n",
      "\n",
      "After merging:\n",
      "Combined data: 2334 rows, from 2000-02-02 00:00:00 to 2021-12-30 00:00:00\n",
      "\n",
      "Creating backup of original file at data\\openbb_cpd_21lbw\\CC.csv.bak\n",
      "Saving merged data to data\\openbb_cpd_21lbw\\CC.csv\n",
      "Merge and sort complete for CC!\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing ticker 5/5: AR\n",
      "Reading data from data\\openbb_cpd_21lbw\\AR.csv...\n",
      "Reading data from data\\openbb_cpd_21lbw(1)\\AR.csv...\n",
      "\n",
      "Before merging:\n",
      "Main data: 2683 rows, from 2011-04-26 00:00:00 to 2021-12-30 00:00:00\n",
      "Alt data: 3060 rows, from 2003-04-16 00:00:00 to 2015-06-05 00:00:00\n",
      "\n",
      "After merging:\n",
      "Combined data: 4713 rows, from 2003-04-16 00:00:00 to 2021-12-30 00:00:00\n",
      "\n",
      "Creating backup of original file at data\\openbb_cpd_21lbw\\AR.csv.bak\n",
      "Saving merged data to data\\openbb_cpd_21lbw\\AR.csv\n",
      "Merge and sort complete for AR!\n",
      "--------------------------------------------------\n",
      "\n",
      "Merge operation completed: Successfully processed 5 out of 5 tickers\n"
     ]
    }
   ],
   "source": [
    "# Process each ticker\n",
    "success_count = 0\n",
    "for i, ticker in enumerate(post_2007_tickers):\n",
    "    print(f\"\\nProcessing ticker {i+1}/{len(post_2007_tickers)}: {ticker}\")\n",
    "    if merge_ticker_data_from_alt_dir(ticker, lbw):\n",
    "        success_count += 1\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\n",
    "    f\"\\nMerge operation completed: Successfully processed {success_count} out of {len(post_2007_tickers)} tickers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1cbc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for tickers without progress files in LBW=21...\n",
      "Found 2 tickers with CSV files but no progress files\n",
      "First 10 tickers: ['6J', 'CT']\n",
      "\n",
      "==================================================\n",
      "Processing ticker 1/2: 6J\n",
      "==================================================\n",
      "Pulling original price data for 6J...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\6J.csv...\n",
      "Created progress file with 1141 processed indices\n",
      "\n",
      "==================================================\n",
      "Processing ticker 2/2: CT\n",
      "==================================================\n",
      "Pulling original price data for CT...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\CT.csv...\n",
      "Created progress file with 1162 processed indices\n",
      "\n",
      "Process complete: Created progress files for 2 out of 2 tickers\n",
      "\n",
      "Searching for tickers without progress files in LBW=126...\n",
      "Found 0 tickers with CSV files but no progress files\n",
      "\n",
      "Process complete: Created progress files for 0 out of 0 tickers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from settings.default import CPD_OPENBB_OUTPUT_FOLDER\n",
    "from data.pull_data import pull_openbb_sample_data\n",
    "\n",
    "\n",
    "def create_missing_progress_files(lbw=21):\n",
    "    \"\"\"\n",
    "    Find tickers that have CPD result files but no progress files,\n",
    "    then create appropriate progress files for them by identifying\n",
    "    which dates/indexes have already been processed.\n",
    "    Excludes tickers that are already in processed_tickers.txt.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lbw : int\n",
    "        Lookback window length (default 21)\n",
    "    \"\"\"\n",
    "    print(f\"\\nSearching for tickers without progress files in LBW={lbw}...\")\n",
    "\n",
    "    # Define paths\n",
    "    main_dir = CPD_OPENBB_OUTPUT_FOLDER(lbw)\n",
    "    processed_tickers_file = os.path.join(main_dir, \"processed_tickers.txt\")\n",
    "\n",
    "    # Read the list of processed tickers to exclude them\n",
    "    processed_tickers = set()\n",
    "    # if os.path.exists(processed_tickers_file):\n",
    "    #     with open(processed_tickers_file, \"r\") as f:\n",
    "    #         processed_tickers = set(line.strip() for line in f if line.strip())\n",
    "    #     print(\n",
    "    #         f\"Found {len(processed_tickers)} tickers in processed_tickers.txt (will exclude these)\"\n",
    "    #     )\n",
    "\n",
    "    # Get all ticker files in the directory\n",
    "    all_files = [\n",
    "        f\n",
    "        for f in os.listdir(main_dir)\n",
    "        if f.endswith(\".csv\")\n",
    "        and not f.endswith(\".bak\")\n",
    "        and not f == \"processed_tickers.txt\"\n",
    "    ]\n",
    "    all_tickers = [os.path.splitext(f)[0] for f in all_files]\n",
    "\n",
    "    # Filter out tickers that are already in processed_tickers.txt\n",
    "    candidates = [\n",
    "        ticker for ticker in all_tickers if ticker not in processed_tickers\n",
    "    ]\n",
    "\n",
    "    # Check which candidates don't have progress files\n",
    "    tickers_without_progress = []\n",
    "    for ticker in candidates:\n",
    "        progress_file = os.path.join(main_dir, f\"{ticker}.csv.progress\")\n",
    "        if not os.path.exists(progress_file):\n",
    "            tickers_without_progress.append(ticker)\n",
    "\n",
    "    print(\n",
    "        f\"Found {len(tickers_without_progress)} tickers with CSV files but no progress files\"\n",
    "    )\n",
    "    if len(tickers_without_progress) > 0:\n",
    "        print(f\"First 10 tickers: {tickers_without_progress[:10]}\")\n",
    "\n",
    "    # Process each ticker without a progress file\n",
    "    success_count = 0\n",
    "    for i, ticker in enumerate(tickers_without_progress):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\n",
    "            f\"Processing ticker {i+1}/{len(tickers_without_progress)}: {ticker}\"\n",
    "        )\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        cpd_file = os.path.join(main_dir, f\"{ticker}.csv\")\n",
    "        progress_file = cpd_file + \".progress\"\n",
    "\n",
    "        try:\n",
    "            # Get original price data\n",
    "            print(f\"Pulling original price data for {ticker}...\")\n",
    "            orig_data = pull_openbb_sample_data(ticker)\n",
    "            orig_data = orig_data[orig_data.index < \"2021-12-31\"]\n",
    "\n",
    "            # Read CPD results file\n",
    "            print(f\"Reading CPD data from {cpd_file}...\")\n",
    "            cpd_data = pd.read_csv(cpd_file, parse_dates=[\"date\"])\n",
    "\n",
    "            # Find which dates have been processed\n",
    "            orig_dates = set(orig_data.index.date)\n",
    "            cpd_dates = set(pd.to_datetime(cpd_data[\"date\"]).dt.date)\n",
    "\n",
    "            # Create a mapping from date to index in original data\n",
    "            orig_data_reset = orig_data.reset_index()\n",
    "            date_to_idx = {\n",
    "                d.date(): i for i, d in enumerate(orig_data_reset[\"date\"])\n",
    "            }\n",
    "\n",
    "            # Create list of processed indices\n",
    "            processed_indices = [\n",
    "                date_to_idx[date] for date in cpd_dates if date in date_to_idx\n",
    "            ]\n",
    "\n",
    "            # Write progress file\n",
    "            with open(progress_file, \"w\") as f:\n",
    "                for idx in sorted(processed_indices):\n",
    "                    f.write(f\"{idx}\\n\")\n",
    "\n",
    "            print(\n",
    "                f\"Created progress file with {len(processed_indices)} processed indices\"\n",
    "            )\n",
    "            success_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {str(e)}\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nProcess complete: Created progress files for {success_count} out of {len(tickers_without_progress)} tickers\"\n",
    "    )\n",
    "    return success_count\n",
    "\n",
    "\n",
    "# Create missing progress files for lookback window 21\n",
    "create_missing_progress_files(lbw=21)\n",
    "create_missing_progress_files(lbw=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing ticker: 6C\n",
      "==================================================\n",
      "Pulling original price data for 6C...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\6C.csv...\n",
      "Found 701 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\6C.csv.progress.bak\n",
      "Identified 701 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 4701, New count: 4701\n",
      "\n",
      "==================================================\n",
      "Processing ticker: 6J\n",
      "==================================================\n",
      "Pulling original price data for 6J...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\6J.csv...\n",
      "Found 4163 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\6J.csv.progress.bak\n",
      "Identified 4163 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 1141, New count: 1141\n",
      "\n",
      "==================================================\n",
      "Processing ticker: 6Z\n",
      "==================================================\n",
      "Pulling original price data for 6Z...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\6Z.csv...\n",
      "Found 3424 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\6Z.csv.progress.bak\n",
      "Identified 3424 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 1750, New count: 1750\n",
      "\n",
      "==================================================\n",
      "Processing ticker: AR\n",
      "==================================================\n",
      "Pulling original price data for AR...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\AR.csv...\n",
      "Found 4734 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\AR.csv.progress.bak\n",
      "Identified 4734 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 0, New count: 0\n",
      "\n",
      "==================================================\n",
      "Processing ticker: CC\n",
      "==================================================\n",
      "Pulling original price data for CC...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\CC.csv...\n",
      "Found 2355 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\CC.csv.progress.bak\n",
      "Identified 2355 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3159, New count: 3159\n",
      "\n",
      "==================================================\n",
      "Processing ticker: CL\n",
      "==================================================\n",
      "Pulling original price data for CL...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\CL.csv...\n",
      "Found 1930 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\CL.csv.progress.bak\n",
      "Identified 1930 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3430, New count: 3430\n",
      "\n",
      "==================================================\n",
      "Processing ticker: CT\n",
      "==================================================\n",
      "Pulling original price data for CT...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\CT.csv...\n",
      "Found 4351 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\CT.csv.progress.bak\n",
      "Identified 4351 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 1162, New count: 1162\n",
      "\n",
      "==================================================\n",
      "Processing ticker: DX\n",
      "==================================================\n",
      "Pulling original price data for DX...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\DX.csv...\n",
      "Found 3427 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\DX.csv.progress.bak\n",
      "Identified 3427 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 2012, New count: 2012\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ES\n",
      "==================================================\n",
      "Pulling original price data for ES...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ES.csv...\n",
      "Found 21 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ES.csv.progress.bak\n",
      "Identified 21 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5358, New count: 5358\n",
      "\n",
      "==================================================\n",
      "Processing ticker: GC\n",
      "==================================================\n",
      "Pulling original price data for GC...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\GC.csv...\n",
      "Found 21 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\GC.csv.progress.bak\n",
      "Identified 21 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5331, New count: 5331\n",
      "\n",
      "==================================================\n",
      "Processing ticker: HG\n",
      "==================================================\n",
      "Pulling original price data for HG...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\HG.csv...\n",
      "Found 21 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\HG.csv.progress.bak\n",
      "Identified 21 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5335, New count: 5335\n",
      "\n",
      "==================================================\n",
      "Processing ticker: HO\n",
      "==================================================\n",
      "Pulling original price data for HO...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\HO.csv...\n",
      "Found 21 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\HO.csv.progress.bak\n",
      "Identified 21 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5333, New count: 5333\n",
      "\n",
      "==================================================\n",
      "Processing ticker: KC\n",
      "==================================================\n",
      "Pulling original price data for KC...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\KC.csv...\n",
      "Found 21 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\KC.csv.progress.bak\n",
      "Identified 21 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5490, New count: 5490\n",
      "\n",
      "==================================================\n",
      "Processing ticker: NG\n",
      "==================================================\n",
      "Pulling original price data for NG...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\NG.csv...\n",
      "Found 3541 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\NG.csv.progress.bak\n",
      "Identified 3541 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 1816, New count: 1816\n",
      "\n",
      "==================================================\n",
      "Processing ticker: NQ\n",
      "==================================================\n",
      "Pulling original price data for NQ...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\NQ.csv...\n",
      "Found 141 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\NQ.csv.progress.bak\n",
      "Identified 141 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5238, New count: 5238\n",
      "\n",
      "==================================================\n",
      "Processing ticker: OJ\n",
      "==================================================\n",
      "Pulling original price data for OJ...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\OJ.csv...\n",
      "Found 2311 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\OJ.csv.progress.bak\n",
      "Identified 2311 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 2778, New count: 2778\n",
      "\n",
      "==================================================\n",
      "Processing ticker: QG\n",
      "==================================================\n",
      "Pulling original price data for QG...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\QG.csv...\n",
      "Found 1711 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\QG.csv.progress.bak\n",
      "Identified 1711 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3178, New count: 3178\n",
      "\n",
      "==================================================\n",
      "Processing ticker: QM\n",
      "==================================================\n",
      "Pulling original price data for QM...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\QM.csv...\n",
      "Found 1921 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\QM.csv.progress.bak\n",
      "Identified 1921 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 2956, New count: 2956\n",
      "\n",
      "==================================================\n",
      "Processing ticker: RB\n",
      "==================================================\n",
      "Pulling original price data for RB...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\RB.csv...\n",
      "Found 1361 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\RB.csv.progress.bak\n",
      "Identified 1361 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3954, New count: 3954\n",
      "\n",
      "==================================================\n",
      "Processing ticker: RF\n",
      "==================================================\n",
      "Pulling original price data for RF...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\RF.csv...\n",
      "Found 1561 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\RF.csv.progress.bak\n",
      "Identified 1561 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3812, New count: 3812\n",
      "\n",
      "==================================================\n",
      "Processing ticker: RP\n",
      "==================================================\n",
      "Pulling original price data for RP...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\RP.csv...\n",
      "Found 1641 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\RP.csv.progress.bak\n",
      "Identified 1641 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3724, New count: 3724\n",
      "\n",
      "==================================================\n",
      "Processing ticker: RY\n",
      "==================================================\n",
      "Pulling original price data for RY...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\RY.csv...\n",
      "Found 101 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\RY.csv.progress.bak\n",
      "Identified 101 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 5255, New count: 5255\n",
      "\n",
      "==================================================\n",
      "Processing ticker: SB\n",
      "==================================================\n",
      "Pulling original price data for SB...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\SB.csv...\n",
      "Found 1721 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\SB.csv.progress.bak\n",
      "Identified 1721 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3753, New count: 3753\n",
      "\n",
      "==================================================\n",
      "Processing ticker: SI\n",
      "==================================================\n",
      "Pulling original price data for SI...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\SI.csv...\n",
      "Found 851 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\SI.csv.progress.bak\n",
      "Identified 851 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 4503, New count: 4503\n",
      "\n",
      "==================================================\n",
      "Processing ticker: SS\n",
      "==================================================\n",
      "Pulling original price data for SS...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\SS.csv...\n",
      "Found 2291 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\SS.csv.progress.bak\n",
      "Identified 2291 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 2448, New count: 2448\n",
      "\n",
      "==================================================\n",
      "Processing ticker: SY\n",
      "==================================================\n",
      "Pulling original price data for SY...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\SY.csv...\n",
      "Found 3311 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\SY.csv.progress.bak\n",
      "Identified 3311 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 1427, New count: 1427\n",
      "\n",
      "==================================================\n",
      "Processing ticker: YM\n",
      "==================================================\n",
      "Pulling original price data for YM...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\YM.csv...\n",
      "Found 1591 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\YM.csv.progress.bak\n",
      "Identified 1591 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3379, New count: 3379\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZB\n",
      "==================================================\n",
      "Pulling original price data for ZB...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZB.csv...\n",
      "Found 1481 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZB.csv.progress.bak\n",
      "Identified 1481 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3866, New count: 3866\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZC\n",
      "==================================================\n",
      "Pulling original price data for ZC...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZC.csv...\n",
      "Found 1711 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZC.csv.progress.bak\n",
      "Identified 1711 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3654, New count: 3654\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZF\n",
      "==================================================\n",
      "Pulling original price data for ZF...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZF.csv...\n",
      "Found 3091 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZF.csv.progress.bak\n",
      "Identified 3091 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 2262, New count: 2262\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZJ\n",
      "==================================================\n",
      "Pulling original price data for ZJ...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZJ.csv...\n",
      "Found 841 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZJ.csv.progress.bak\n",
      "Identified 841 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 4646, New count: 4646\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZN\n",
      "==================================================\n",
      "Pulling original price data for ZN...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZN.csv...\n",
      "Found 1151 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZN.csv.progress.bak\n",
      "Identified 1151 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 4190, New count: 4190\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZR\n",
      "==================================================\n",
      "Pulling original price data for ZR...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZR.csv...\n",
      "Found 991 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZR.csv.progress.bak\n",
      "Identified 991 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 4596, New count: 4596\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZS\n",
      "==================================================\n",
      "Pulling original price data for ZS...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZS.csv...\n",
      "Found 5357 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZS.csv.progress.bak\n",
      "Identified 5357 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 0, New count: 0\n",
      "\n",
      "==================================================\n",
      "Processing ticker: ZW\n",
      "==================================================\n",
      "Pulling original price data for ZW...\n",
      "Reading CPD data from data\\openbb_cpd_21lbw\\ZW.csv...\n",
      "Found 1551 missing dates in CPD file\n",
      "Created backup of progress file at data\\openbb_cpd_21lbw\\ZW.csv.progress.bak\n",
      "Identified 1551 indexes to remove from progress file\n",
      "Sample indexes to remove: [0, 1, 2, 3, 4] ...\n",
      "Removed 0 entries from progress file\n",
      "Original count: 3826, New count: 3826\n",
      "\n",
      "Processing complete: Successfully processed 35 out of 35 tickers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from settings.default import CPD_OPENBB_OUTPUT_FOLDER, OPENBB_2003_TICKERS\n",
    "from data.pull_data import pull_openbb_sample_data\n",
    "from mom_trans.data_prep import calc_returns\n",
    "\n",
    "\n",
    "def find_and_remove_missing_date_indexes(ticker, lbw=21):\n",
    "    \"\"\"\n",
    "    Find missing dates between CPD results and original price data,\n",
    "    then remove those indexes from the progress file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ticker : str\n",
    "        Ticker symbol\n",
    "    lbw : int\n",
    "        Lookback window length (default 21)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing ticker: {ticker}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Define paths\n",
    "    main_dir = CPD_OPENBB_OUTPUT_FOLDER(lbw)\n",
    "    cpd_file = os.path.join(main_dir, f\"{ticker}.csv\")\n",
    "    progress_file = cpd_file + \".progress\"\n",
    "\n",
    "    # Check if files exist\n",
    "    if not os.path.exists(cpd_file):\n",
    "        print(f\"CPD file for {ticker} doesn't exist in {main_dir}\")\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(progress_file):\n",
    "        print(f\"Progress file for {ticker} doesn't exist\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # Step 1: Get original price data\n",
    "        print(f\"Pulling original price data for {ticker}...\")\n",
    "        orig_data = pull_openbb_sample_data(ticker)\n",
    "        orig_data = orig_data[\n",
    "            orig_data.index < \"2021-12-31\"\n",
    "        ]  # Same filter as used previously\n",
    "\n",
    "        # Step 2: Read CPD results file\n",
    "        print(f\"Reading CPD data from {cpd_file}...\")\n",
    "        cpd_data = pd.read_csv(cpd_file, parse_dates=[\"date\"])\n",
    "\n",
    "        # Step 3: Find missing dates\n",
    "        orig_dates = set(orig_data.index.date)\n",
    "        cpd_dates = set(pd.to_datetime(cpd_data[\"date\"]).dt.date)\n",
    "\n",
    "        missing_dates = orig_dates - cpd_dates\n",
    "\n",
    "        print(f\"Found {len(missing_dates)} missing dates in CPD file\")\n",
    "\n",
    "        if not missing_dates:\n",
    "            print(\"No missing dates found. Progress file remains unchanged.\")\n",
    "            return True\n",
    "\n",
    "        # Step 4: Read progress file\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            indices = [int(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "        # Create backup of original progress file\n",
    "        with open(progress_file + \".bak\", \"w\") as f:\n",
    "            for idx in indices:\n",
    "                f.write(f\"{idx}\\n\")\n",
    "\n",
    "        print(f\"Created backup of progress file at {progress_file}.bak\")\n",
    "\n",
    "        # Step 5: For each missing date, remove the corresponding indices\n",
    "        # The indexes in the progress file correspond to positions in the original data\n",
    "        # First, create a mapping from date to index in original data\n",
    "        orig_data_reset = orig_data.reset_index()\n",
    "        date_to_idx = {\n",
    "            d.date(): i for i, d in enumerate(orig_data_reset[\"date\"])\n",
    "        }\n",
    "\n",
    "        # Find indices to remove\n",
    "        indices_to_remove = []\n",
    "        for missing_date in missing_dates:\n",
    "            if missing_date in date_to_idx:\n",
    "                indices_to_remove.append(date_to_idx[missing_date])\n",
    "\n",
    "        print(\n",
    "            f\"Identified {len(indices_to_remove)} indexes to remove from progress file\"\n",
    "        )\n",
    "        if len(indices_to_remove) > 0:\n",
    "            print(\n",
    "                f\"Sample indexes to remove: {sorted(indices_to_remove)[:5]} ...\"\n",
    "            )\n",
    "\n",
    "            # Step 6: Filter out these indices from the progress file\n",
    "            original_count = len(indices)\n",
    "            filtered_indices = [\n",
    "                idx for idx in indices if idx not in indices_to_remove\n",
    "            ]\n",
    "            removed_count = original_count - len(filtered_indices)\n",
    "\n",
    "            # Step 7: Write the filtered indices back to the progress file\n",
    "            with open(progress_file, \"w\") as f:\n",
    "                for idx in sorted(filtered_indices):\n",
    "                    f.write(f\"{idx}\\n\")\n",
    "\n",
    "            print(f\"Removed {removed_count} entries from progress file\")\n",
    "            print(\n",
    "                f\"Original count: {original_count}, New count: {len(filtered_indices)}\"\n",
    "            )\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Process each ticker\n",
    "tickers = OPENBB_2003_TICKERS\n",
    "lbw = 21\n",
    "\n",
    "success_count = 0\n",
    "for ticker in tickers:\n",
    "    if find_and_remove_missing_date_indexes(ticker, lbw):\n",
    "        success_count += 1\n",
    "\n",
    "print(\n",
    "    f\"\\nProcessing complete: Successfully processed {success_count} out of {len(tickers)} tickers\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
